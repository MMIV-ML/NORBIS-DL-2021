{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false,
     "source_hidden": false
    }
   },
   "source": [
    "# Building a state of the art bacterial classifier with fastai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "> ***This is a modified version of the notebook [Bacteria Classification with fast.ai](https://ml-showcase.paperspace.com/projects/bacteria-classification-fast-ai-dibas) created by The Gradient Team at Paperspace***. \n",
    "\n",
    "> The code has been slightly updated to support the most recent fastai version and some additional content added. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "The fast.ai library has been breaking records as students use it to produce state of the art results on a myriad of tasks. Some examples given in the course include environmental sound classification and handwritten devanagari prediction.\n",
    "\n",
    "In this notebook we'll use the library for state of the art bacteria classification with the [DIBaS (Digital Image of Bacterial Species) dataset](http://misztal.edu.pl/software/databases/dibas/). See also _ZieliÅ„ski, Bartosz, et al. [\"Deep learning approach to bacterial colony classification.\"](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0184554) PloS one 12.9 (2017)_ paper link]. DIBaS contains 660 images, with 33 different genera and species of bacteria.\n",
    "\n",
    "You can also check out the full blog post on [Building a Bacterial Classifier with fast.ai](https://blog.paperspace.com/building-a-state-of-the-art-bacterial-classifier-with-paperspace-gradient-and-fast-ai/) by Harsh Sikka."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: Running this notebook outside Gradient requires some modifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "## Install and load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "!pip install -Uqq fastbook\n",
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "from fastbook import *\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "# Download and load bacteria dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('/storage/dibas_zips'):\n",
    "    os.makedirs('/storage/dibas_zips')\n",
    "\n",
    "if not os.path.exists('/storage/dibas_images'):\n",
    "    os.makedirs('/storage/dibas_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('/storage/dibas_zips/Acinetobacter.baumanii.zip'):\n",
    "    # Parse the webpage; images are saved in a separate .zip file for each strain of bacteria\n",
    "    url = 'http://misztal.edu.pl/software/databases/dibas/'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    links = [tag['href'] for tag in soup.findAll('a')]\n",
    "\n",
    "    for link in links:\n",
    "        if \".zip\" in link:\n",
    "            file_name = link.partition(\"/dibas/\")[2]\n",
    "            urllib.request.urlretrieve(link, '/storage/dibas_zips/' + file_name) \n",
    "            zip_ref = zipfile.ZipFile('/storage/dibas_zips/' + file_name, 'r')\n",
    "            zip_ref.extractall('/storage/dibas_images/')   \n",
    "            zip_ref.close()\n",
    "            print(\"Downloaded and extracted: \" + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "path = Path('/storage/dibas_images/')\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "### Check the images and delete the ones that won't load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "failed = verify_images(path.ls(file_exts='.tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "failed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the ones that didn't load:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "failed.map(Path.unlink)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "def label_func(fn):\n",
    "    return str(fn.name).split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "item_tfms = Resize(400, method='pad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "batch_tfms = [Resize(300, method='pad'), Flip(), Zoom(),\n",
    "              Contrast(), Rotate(30), Normalize.from_stats(*imagenet_stats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "db = DataBlock(blocks=[ImageBlock(), CategoryBlock()], \n",
    "                get_items= partial(get_image_files, recurse=False),\n",
    "                get_y = label_func,\n",
    "                splitter=RandomSplitter(valid_pct=0.3),\n",
    "                item_tfms=item_tfms,\n",
    "                batch_tfms=batch_tfms\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "dls = db.dataloaders(path, bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "dls.show_batch(figsize=(16,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet34, metrics=[accuracy, error_rate])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find a good learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "lr_min, lr_steep = learn.lr_find(suggestions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "lr_min, lr_steep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "learn.fine_tune(10, base_lr=lr_min/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "learn.show_results(figsize=(16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "interp.plot_top_losses(4, figsize=(16,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix(figsize=(16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "0.015000 * len(learn.dls.valid_ds.items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only three errors among the 200 images in the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. To compare with the results of the original paper one should design a more careful validatation setup. In the paper they did a 25 fold cross-validation. Try to do something similar (but with a smaller number of folds if you don't have time for 25 training runs).\n",
    "2. Try other CNN network architectures.\n",
    "3. Look into other data augmentation strategies.\n",
    "4. Add class activation maps (CAM and/or gradCAM) to investigate what features the model used to make its classifications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
